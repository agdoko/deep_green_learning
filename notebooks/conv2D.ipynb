{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Copy & Paste code from .py files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GwPuvA-e_Ii0"
      },
      "outputs": [],
      "source": [
        "# Required imports\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score\n",
        "# Required imports\n",
        "import ee\n",
        "import numpy as np\n",
        "\n",
        "# Required imports\n",
        "import google\n",
        "from google.colab import auth\n",
        "import folium\n",
        "import requests\n",
        "import io\n",
        "from folium import plugins\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Demq4u4v_4Gs"
      },
      "outputs": [],
      "source": [
        "# Standard authentication cell\n",
        "auth.authenticate_user()\n",
        "credentials, project_id = google.auth.default()\n",
        "ee.Initialize(credentials, project='semiotic-garden-395711')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ffKBbpXe_xR4"
      },
      "outputs": [],
      "source": [
        "# Required imports\n",
        "import requests\n",
        "from typing import Iterable\n",
        "\n",
        "\"\"\" Defines the functions used to get the data for initial model training. \"\"\"\n",
        "\n",
        "# Remaps the target land classification from mutli-class to binary\n",
        "def get_target_image(target) -> ee.Image:\n",
        "    \"\"\" Buckets multi-class land cover classifications into 2 classes:\n",
        "    1 = forest\n",
        "    0 = non-forest \"\"\"\n",
        "    # Remap the ESA classifications into the Dynamic World classifications\n",
        "    fromValues = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
        "    toValues = [1, 1, 1, 1, 1, 0, 0, 0,0, 0, 0,0,0,0,0,0,0]\n",
        "    return (\n",
        "        target.first()\n",
        "        .select(\"LC_Type1\")\n",
        "        .remap(fromValues, toValues)\n",
        "        .rename(\"landcover\")\n",
        "        .unmask(0)  # fill missing values with 0 (water)\n",
        "        .byte()  # 9 classifications fit into an unsinged 8-bit integer\n",
        "    )\n",
        "\n",
        "# Getting the target sample points, equally stratified across both classes\n",
        "def sample_points(\n",
        "    region: ee.Geometry, image: ee.Image, points_per_class: int, scale: int\n",
        ") -> Iterable[tuple[float, float]]:\n",
        "    \"\"\" Applies the stratified sampling algorithm to the given target image.\"\"\"\n",
        "    points = image.stratifiedSample(\n",
        "        points_per_class,\n",
        "        region=region,\n",
        "        scale=scale,\n",
        "        geometries=True,\n",
        "    )\n",
        "    for point in points.toList(points.size()).getInfo():\n",
        "        yield point[\"geometry\"][\"coordinates\"]\n",
        "\n",
        "# OBSOLETE\n",
        "# Getting the coordinates for the target points using Ana's random 100 approach\n",
        "def get_coordinates(points):\n",
        "    \"\"\" Returns a dictionary of square pixel coordinates for the target points. \"\"\"\n",
        "    target_dict = {}\n",
        "    numb = 1\n",
        "\n",
        "    # Iterating through the global image to generate stratified sampling coordinates\n",
        "    for point in points:\n",
        "        target_dict[f\"P{numb}\"] = list(point)\n",
        "        numb +=1\n",
        "\n",
        "    return target_dict\n",
        "\n",
        "# TO DO - make this more robust. it works for about 80 points but can break past 100\n",
        "# Getting the coordinates for the target points using Felix' stratified approach\n",
        "def get_coordinates_felix(polygon, target):\n",
        "    \"\"\" Returns a dictionary of square pixel coordinates for the target points. \"\"\"\n",
        "    # Defining the region of interest\n",
        "    region = ee.Geometry.Polygon(polygon)\n",
        "\n",
        "    # Getting the target image and creating a dictionary to store the coordinates\n",
        "    labels_image = get_target_image(target)\n",
        "    target_dict = {}\n",
        "    numb = 1\n",
        "\n",
        "    # Iterating through the global image to generate stratified sampling coordinates\n",
        "    for point in sample_points(region, labels_image, points_per_class=2, scale=500):\n",
        "        target_dict[f\"P{numb}\"] = point\n",
        "        numb +=1\n",
        "\n",
        "    return target_dict\n",
        "\n",
        "# Extracting the coordinates\n",
        "\n",
        "# Taking the coordinates and getting the features data for the target points\n",
        "def get_data(target_dict, year, feature_bands, target):\n",
        "    \"\"\" Get the feature and target data, both as ndarrays. \"\"\"\n",
        "\n",
        "    ### FEATURES ###\n",
        "\n",
        "    # Initialize an empty list to hold the images and skipped points\n",
        "    stacked_feature_list = []\n",
        "    skipped_points = []\n",
        "\n",
        "    # Debugging counter for featuress\n",
        "    features_counter = 0\n",
        "\n",
        "    # Loop over each year from year\n",
        "    for point in target_dict:\n",
        "        # Get the picked point and create a 500m x 500m square around it\n",
        "        picked_point = ee.Geometry.Point(target_dict[point])\n",
        "        square = picked_point.buffer(250).bounds()\n",
        "\n",
        "        # Define image collection features\n",
        "        image_collection_features = (ee.ImageCollection(\"COPERNICUS/S2_HARMONIZED\")\n",
        "            .filterDate(f\"{year}-1-1\", f\"{year+3}-12-31\")\n",
        "            .filterBounds(square)\n",
        "            .select(feature_bands)\n",
        "            .sort('system:time_start'))\n",
        "\n",
        "        # Check size of the image collection\n",
        "        count = image_collection_features.size().getInfo()\n",
        "        if count == 0:\n",
        "            print(f\"Skipping point: {point}\")\n",
        "            skipped_points.append(point)\n",
        "            continue\n",
        "\n",
        "        # Get the first image\n",
        "        image_features = image_collection_features.first()\n",
        "\n",
        "        # Clip the gotten image to the 500m x 500m square\n",
        "        c_img_features = image_features.clip(square)\n",
        "\n",
        "        # Get the download url for the clipped image\n",
        "        url = c_img_features.getDownloadUrl({\n",
        "            'scale': 10, # Because the feature satellite images are 10m x 10m per pixel in resolution\n",
        "            'format': 'NPY' # numpy\n",
        "            })\n",
        "\n",
        "        # Get the image as a numpy array\n",
        "        image_array_features = requests.get(url)\n",
        "        image_array_features = np.load(io.BytesIO(image_array_features.content))\n",
        "\n",
        "        # Creating the NDVI array - NDVI is an index used for detecting forest in the academic literature\n",
        "        # Extract B4 (Red) and B8 (NIR)\n",
        "        B4 = image_array_features['B4'].astype(float)\n",
        "        B8 = image_array_features['B8'].astype(float)\n",
        "\n",
        "        # Calculate NDVI - basically the normalised difference between Red and NIR bands\n",
        "        NDVI = (B8 - B4) / (B8 + B4 + 1e-10)  # adding a small constant to avoid division by zero\n",
        "\n",
        "        # Append the numpy array to the list\n",
        "        stacked_feature_list.append(NDVI)\n",
        "        print(stacked_feature_list[-1]) # Uncomment to see the numpy array\n",
        "        print(f\"Appending feature {features_counter} with shape {NDVI.shape}\") # Uncomment to see the shape of the numpy array\n",
        "        features_counter += 1\n",
        "\n",
        "    # Apply cropping to the numpy array to ensure consistent shape\n",
        "    cropped_arrays_features = []\n",
        "\n",
        "    for arr in stacked_feature_list:\n",
        "        cropped_features = arr[:50, :50]\n",
        "        cropped_arrays_features.append(cropped_features)\n",
        "\n",
        "    feature_stacked_array = np.stack(cropped_arrays_features, axis=0)\n",
        "\n",
        "    ### TARGETS ###\n",
        "\n",
        "    # Account for the fact that some points were skipped in feature dataset, and we must maintain matching target points that remain\n",
        "    new_target_dict = {k: v for k, v in target_dict.items() if k not in skipped_points}\n",
        "\n",
        "    # Initialize an empty list to hold the images and skipped points\n",
        "    stacked_target_list = []\n",
        "\n",
        "    # Debugging counter for targets\n",
        "    target_counter = 0\n",
        "\n",
        "    # Loop over each year from year\n",
        "    for point in new_target_dict:\n",
        "        # Get the picked point and create a 500m x 500m square around it\n",
        "        picked_point = ee.Geometry.Point(target_dict[point])\n",
        "        square = picked_point.buffer(250).bounds()\n",
        "\n",
        "        # Clip the gotten image to the 500m x 500m square\n",
        "        c_img_target = target.clip(square)\n",
        "\n",
        "        # Get the download url for the clipped image\n",
        "        url = c_img_target.getDownloadUrl({\n",
        "            'scale': 500, # Because the target satellite images are 500m x 500m per pixel in resolution\n",
        "            'format': 'NPY' # numpy\n",
        "            })\n",
        "\n",
        "        # Get the image as a numpy array\n",
        "        image_array_targets = requests.get(url)\n",
        "        image_array_targets = np.load(io.BytesIO(image_array_targets.content))\n",
        "\n",
        "        # Append the numpy array to the list\n",
        "        stacked_target_list.append(image_array_targets)\n",
        "        print(stacked_target_list[-1]) # Uncomment to see the numpy array\n",
        "        print(f\"Appending target {target_counter} with shape {image_array_targets.shape}\") # Uncomment to see the shape of the numpy array\n",
        "        target_counter += 1\n",
        "\n",
        "    # Apply cropping to the numpy array to ensure consistent shape\n",
        "    cropped_arrays_targets = []\n",
        "\n",
        "    for arr in stacked_target_list:\n",
        "        cropped_targets = arr[:3, :3]\n",
        "        cropped_arrays_targets.append(cropped_targets)\n",
        "\n",
        "    target_stacked_array = np.stack(cropped_arrays_targets, axis=0)\n",
        "\n",
        "    ### TRAINING AND TEST DATASETS ###\n",
        "\n",
        "    # Separating the feature and target arrays into training and test datasets using 80/20 split\n",
        "\n",
        "    depth = target_stacked_array.shape[0]\n",
        "    split_index = int(depth * 0.8)  # 80% for training\n",
        "\n",
        "    # Train-test split\n",
        "    train_target = target_stacked_array[:split_index]\n",
        "    test_target = target_stacked_array[split_index:]\n",
        "\n",
        "    train_feature = feature_stacked_array[:split_index]\n",
        "    test_feature = feature_stacked_array[split_index:]\n",
        "    print(train_feature.shape, train_target.shape, test_feature.shape, test_target.shape)\n",
        "    return train_feature, train_target, test_feature, test_target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOdQItMp_0cC",
        "outputId": "a1c2c713-c7bf-4f68-e961-e525e9d5410b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         ... 0.02518451 0.         0.        ]\n",
            " [0.02650442 0.04333438 0.02870115 ... 0.02841443 0.         0.        ]\n",
            " [0.03466287 0.03767661 0.03633697 ... 0.02888828 0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.06868638 ... 0.05282274 0.04320747 0.        ]\n",
            " [0.         0.         0.06079976 ... 0.03807068 0.03906546 0.        ]\n",
            " [0.         0.         0.04646775 ... 0.         0.         0.        ]]\n",
            "Appending feature 0 with shape (52, 53)\n",
            "[[ 0.         -0.08589744 -0.10251451 ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.         -0.10077519 -0.10707333 ... -0.09554974 -0.09920635\n",
            "  -0.06961614]\n",
            " [ 0.         -0.1092437  -0.09639344 ... -0.08996089 -0.05905256\n",
            "  -0.06970509]\n",
            " ...\n",
            " [ 0.         -0.06565657 -0.06102117 ... -0.08894536 -0.08881789\n",
            "   0.        ]\n",
            " [ 0.         -0.07228158 -0.09011809 ... -0.08359923 -0.09102564\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ... -0.07594129 -0.08007687\n",
            "   0.        ]]\n",
            "Appending feature 1 with shape (52, 52)\n",
            "[[0.         0.         0.         ... 0.69014085 0.68105601 0.        ]\n",
            " [0.63937208 0.63411514 0.58545092 ... 0.68818782 0.69623749 0.        ]\n",
            " [0.62852405 0.64644436 0.63157895 ... 0.68176255 0.70372977 0.        ]\n",
            " ...\n",
            " [0.68675568 0.68562345 0.68592058 ... 0.69236499 0.67338869 0.67179487]\n",
            " [0.66971081 0.68280347 0.68709907 ... 0.68819921 0.66490566 0.67219292]\n",
            " [0.67820464 0.68110236 0.68056097 ... 0.66212534 0.66620785 0.67671631]]\n",
            "Appending feature 2 with shape (51, 51)\n",
            "[[0.         0.         0.         ... 0.05669599 0.         0.        ]\n",
            " [0.         0.         0.         ... 0.06121948 0.         0.        ]\n",
            " [0.05605125 0.05155343 0.04688736 ... 0.06666667 0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.04576108 ... 0.03820375 0.04031813 0.05848343]\n",
            " [0.         0.         0.04998793 ... 0.         0.         0.        ]\n",
            " [0.         0.         0.04405552 ... 0.         0.         0.        ]]\n",
            "Appending feature 3 with shape (53, 53)\n",
            "[[(0,) (0,) (0,)]\n",
            " [(0,) (0,) (0,)]\n",
            " [(0,) (0,) (0,)]]\n",
            "Appending target 0 with shape (3, 3)\n",
            "[[(0,) (0,) (0,)]\n",
            " [(0,) (0,) (0,)]\n",
            " [(0,) (0,) (0,)]]\n",
            "Appending target 1 with shape (3, 3)\n",
            "[[(0,) (0,) (0,)]\n",
            " [(1,) (1,) (1,)]\n",
            " [(0,) (0,) (0,)]]\n",
            "Appending target 2 with shape (3, 3)\n",
            "[[(0,) (0,) (0,)]\n",
            " [(0,) (1,) (1,)]\n",
            " [(0,) (0,) (0,)]]\n",
            "Appending target 3 with shape (3, 3)\n",
            "(3, 50, 50) (3, 3, 3) (1, 50, 50) (1, 3, 3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([[[ 0.        ,  0.        ,  0.        , ...,  0.02173291,\n",
              "           0.02023879,  0.02179392],\n",
              "         [ 0.02650442,  0.04333438,  0.02870115, ...,  0.02335746,\n",
              "           0.02036532,  0.02074043],\n",
              "         [ 0.03466287,  0.03767661,  0.03633697, ...,  0.02715171,\n",
              "           0.02129933,  0.02142616],\n",
              "         ...,\n",
              "         [ 0.        ,  0.        ,  0.08288791, ...,  0.02973736,\n",
              "           0.02871025,  0.04002982],\n",
              "         [ 0.        ,  0.        ,  0.07696074, ...,  0.02606466,\n",
              "           0.02642676,  0.03320599],\n",
              "         [ 0.        ,  0.        ,  0.06868638, ...,  0.02209172,\n",
              "           0.02735605,  0.03792798]],\n",
              " \n",
              "        [[ 0.        , -0.08589744, -0.10251451, ...,  0.        ,\n",
              "           0.        ,  0.        ],\n",
              "         [ 0.        , -0.10077519, -0.10707333, ..., -0.10919921,\n",
              "          -0.09079118, -0.09554974],\n",
              "         [ 0.        , -0.1092437 , -0.09639344, ..., -0.11477573,\n",
              "          -0.09520683, -0.08996089],\n",
              "         ...,\n",
              "         [ 0.        , -0.0591195 , -0.07047619, ..., -0.07860825,\n",
              "          -0.08461538, -0.09390863],\n",
              "         [ 0.        , -0.06809584, -0.06658212, ..., -0.0793854 ,\n",
              "          -0.0835443 , -0.08365019],\n",
              "         [ 0.        , -0.06565657, -0.06102117, ..., -0.09857328,\n",
              "          -0.10269576, -0.08894536]],\n",
              " \n",
              "        [[ 0.        ,  0.        ,  0.        , ...,  0.67985075,\n",
              "           0.69014085,  0.68105601],\n",
              "         [ 0.63937208,  0.63411514,  0.58545092, ...,  0.6754717 ,\n",
              "           0.68818782,  0.69623749],\n",
              "         [ 0.62852405,  0.64644436,  0.63157895, ...,  0.65794066,\n",
              "           0.68176255,  0.70372977],\n",
              "         ...,\n",
              "         [ 0.68126888,  0.68246968,  0.67485822, ...,  0.68587571,\n",
              "           0.67017544,  0.65977742],\n",
              "         [ 0.68675568,  0.68562345,  0.68592058, ...,  0.70136054,\n",
              "           0.69236499,  0.67338869],\n",
              "         [ 0.66971081,  0.68280347,  0.68709907, ...,  0.69683258,\n",
              "           0.68819921,  0.66490566]]]),\n",
              " array([[[(0,), (0,), (0,)],\n",
              "         [(0,), (0,), (0,)],\n",
              "         [(0,), (0,), (0,)]],\n",
              " \n",
              "        [[(0,), (0,), (0,)],\n",
              "         [(0,), (0,), (0,)],\n",
              "         [(0,), (0,), (0,)]],\n",
              " \n",
              "        [[(0,), (0,), (0,)],\n",
              "         [(1,), (1,), (1,)],\n",
              "         [(0,), (0,), (0,)]]], dtype=[('landcover', 'u1')]),\n",
              " array([[[0.        , 0.        , 0.        , ..., 0.05606778,\n",
              "          0.05866536, 0.0611944 ],\n",
              "         [0.        , 0.        , 0.        , ..., 0.06529805,\n",
              "          0.05793939, 0.05734811],\n",
              "         [0.05605125, 0.05155343, 0.04688736, ..., 0.05970516,\n",
              "          0.04947821, 0.0617737 ],\n",
              "         ...,\n",
              "         [0.        , 0.        , 0.04625045, ..., 0.05758349,\n",
              "          0.04239964, 0.04795975],\n",
              "         [0.        , 0.        , 0.04211158, ..., 0.04975674,\n",
              "          0.04967219, 0.04634146],\n",
              "         [0.        , 0.        , 0.04300048, ..., 0.05008329,\n",
              "          0.04975179, 0.04682164]]]),\n",
              " array([[[(0,), (0,), (0,)],\n",
              "         [(0,), (1,), (1,)],\n",
              "         [(0,), (0,), (0,)]]], dtype=[('landcover', 'u1')]))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\"\"\" Provides the setpoint values according to which the data will be collected. \"\"\"\n",
        "\n",
        "# # Initialise the Earth Engine module.\n",
        "# ee.Initialize()\n",
        "\n",
        "# Defining the main year around which data will be collected\n",
        "f_date = '2017'\n",
        "\n",
        "# Defining the target ImageCollection, filtered by the main year\n",
        "target = (ee.ImageCollection(\"MODIS/061/MCD12Q1\")\n",
        "          .filterDate(f_date)\n",
        "          .sort('system:time_start'))  # Sort by time to get earliest image\n",
        "\n",
        "# Oversimplified North America region.\n",
        "polygon = [[[-145.7, 63.2], [-118.1, 22.3], [-78.2, 5.6], [-52.9, 47.6]]]\n",
        "\n",
        "# Global polygon, while minimising the amount of water\n",
        "#polygon = [[[-180, -60], [180, -60], [180, 85], [-180, 85], [-180, -60]]]\n",
        "\n",
        "# Select the feature bands\n",
        "feature_bands = [\"B4\", \"B8\"]\n",
        "\n",
        "# Running the function get_coordinates to test the script\n",
        "get_data(get_coordinates_felix(polygon, target), int(f_date), feature_bands, get_target_image(target))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mYxkkZz3ATTC"
      },
      "outputs": [],
      "source": [
        "# Required imports\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import Sequential, layers\n",
        "\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.optimizers import Adam, Nadam\n",
        "# from tensorflow.keras import applications, optimizers\n",
        "# from tensorflow.keras.applications import InceptionResNetV2\n",
        "# from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "# from tensorflow.keras.utils import model_to_dot, plot_model, image_dataset_from_directory\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, LearningRateScheduler\n",
        "# from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, ZeroPadding2D, Dropout\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "\n",
        "# Defining the majority pooling function for the baseline model\n",
        "def majority_pool(array):\n",
        "    dt = np.dtype([(\"ndvi\", np.int32)])\n",
        "    pooled_array = np.zeros((array.shape[0], 3, 3), dtype=dt)\n",
        "\n",
        "    step_x = step_y = 16\n",
        "\n",
        "    for n in range(array.shape[0]):\n",
        "        for i in range(3):\n",
        "            x_start = i * step_x\n",
        "            for j in range(3):\n",
        "                y_start = j * step_y\n",
        "                quadrant = array[n, x_start:x_start+step_x, y_start:y_start+step_y]\n",
        "                majority = np.sum(quadrant) > (step_x * step_y // 2)\n",
        "                pooled_array[n, i, j]['ndvi'] = int(majority)\n",
        "\n",
        "    return pooled_array\n",
        "\n",
        "# Define the baseline model\n",
        "def baseline(test_feature):\n",
        "    \"\"\" Baseline model that uses majority pooling on a threshold NDVI value. \"\"\"\n",
        "    mask_ndvi = test_feature >= 0.6\n",
        "    NDVI_bucketed = np.where(mask_ndvi, 1, 0)\n",
        "    y_pred_baseline = majority_pool(NDVI_bucketed)\n",
        "    return y_pred_baseline\n",
        "\n",
        "#Convert a structured ndarray to a standard ndarray and expand dimensions to align with CNN input.\n",
        "def process_and_expand(structured_array,  dtype=np.float32):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        structured_array (numpy.ndarray): The structured array to convert.\n",
        "        field_name (str): The name of the field to extract from the structured array.\n",
        "        dtype (numpy.dtype, optional): The desired dtype for the output array. Defaults to np.float32.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The converted and expanded standard ndarray.\n",
        "    \"\"\"\n",
        "    standard_array = np.array(structured_array, dtype=dtype)\n",
        "    expanded_array = np.expand_dims(standard_array, axis=-1)\n",
        "    return expanded_array\n",
        "\n",
        "\n",
        "# Define and train the CNN model\n",
        "def train_cnn(train_feature_expanded, train_target_expanded):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(50, 50, 1)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_feature_expanded, train_target_expanded, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Run a prediction from the CNN model\n",
        "def predict_cnn(model, test_feature):\n",
        "    predictions = model.predict(test_feature)\n",
        "    # Round predictions to get binary classification output\n",
        "    rounded_predictions = [round(x[0]) for x in predictions]\n",
        "    return rounded_predictions\n",
        "\n",
        "# predictions = predict_cnn(trained_model, test_feature_reshaped)\n",
        "# print(\"Predictions:\", predictions)\n",
        "\n",
        "# Define the evaluation function\n",
        "def evaluate(test_target, y_pred):\n",
        "    \"\"\" Evaluates the model using the F1 score. \"\"\"\n",
        "    # Reshape your arrays into 1D arrays\n",
        "    #true_values_1D = test_target.reshape(-1)\n",
        "    #pred_values_1D = y_pred.reshape(-1)\n",
        "\n",
        "    true_values_1D = test_target[\"landcover\"].flatten()\n",
        "    pred_values_1D = y_pred['ndvi'].flatten()\n",
        "\n",
        "    # Calculate F1 score\n",
        "    f1 = f1_score(true_values_1D, pred_values_1D)\n",
        "\n",
        "    print(\"F1 Score:\", f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcwpd4kUNbWe",
        "outputId": "4de1bf82-dfa1-404f-a66e-04fa3c62c278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         ... 0.02518451 0.         0.        ]\n",
            " [0.02650442 0.04333438 0.02870115 ... 0.02841443 0.         0.        ]\n",
            " [0.03466287 0.03767661 0.03633697 ... 0.02888828 0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.06868638 ... 0.05282274 0.04320747 0.        ]\n",
            " [0.         0.         0.06079976 ... 0.03807068 0.03906546 0.        ]\n",
            " [0.         0.         0.04646775 ... 0.         0.         0.        ]]\n",
            "Appending feature 0 with shape (52, 53)\n",
            "[[ 0.         -0.08589744 -0.10251451 ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.         -0.10077519 -0.10707333 ... -0.09554974 -0.09920635\n",
            "  -0.06961614]\n",
            " [ 0.         -0.1092437  -0.09639344 ... -0.08996089 -0.05905256\n",
            "  -0.06970509]\n",
            " ...\n",
            " [ 0.         -0.06565657 -0.06102117 ... -0.08894536 -0.08881789\n",
            "   0.        ]\n",
            " [ 0.         -0.07228158 -0.09011809 ... -0.08359923 -0.09102564\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ... -0.07594129 -0.08007687\n",
            "   0.        ]]\n",
            "Appending feature 1 with shape (52, 52)\n",
            "[[0.         0.         0.         ... 0.69014085 0.68105601 0.        ]\n",
            " [0.63937208 0.63411514 0.58545092 ... 0.68818782 0.69623749 0.        ]\n",
            " [0.62852405 0.64644436 0.63157895 ... 0.68176255 0.70372977 0.        ]\n",
            " ...\n",
            " [0.68675568 0.68562345 0.68592058 ... 0.69236499 0.67338869 0.67179487]\n",
            " [0.66971081 0.68280347 0.68709907 ... 0.68819921 0.66490566 0.67219292]\n",
            " [0.67820464 0.68110236 0.68056097 ... 0.66212534 0.66620785 0.67671631]]\n",
            "Appending feature 2 with shape (51, 51)\n",
            "[[0.         0.         0.         ... 0.05669599 0.         0.        ]\n",
            " [0.         0.         0.         ... 0.06121948 0.         0.        ]\n",
            " [0.05605125 0.05155343 0.04688736 ... 0.06666667 0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.04576108 ... 0.03820375 0.04031813 0.05848343]\n",
            " [0.         0.         0.04998793 ... 0.         0.         0.        ]\n",
            " [0.         0.         0.04405552 ... 0.         0.         0.        ]]\n",
            "Appending feature 3 with shape (53, 53)\n",
            "[[(0,) (0,) (0,)]\n",
            " [(0,) (0,) (0,)]\n",
            " [(0,) (0,) (0,)]]\n",
            "Appending target 0 with shape (3, 3)\n",
            "[[(0,) (0,) (0,)]\n",
            " [(0,) (0,) (0,)]\n",
            " [(0,) (0,) (0,)]]\n",
            "Appending target 1 with shape (3, 3)\n",
            "[[(0,) (0,) (0,)]\n",
            " [(1,) (1,) (1,)]\n",
            " [(0,) (0,) (0,)]]\n",
            "Appending target 2 with shape (3, 3)\n",
            "[[(0,) (0,) (0,)]\n",
            " [(0,) (1,) (1,)]\n",
            " [(0,) (0,) (0,)]]\n",
            "Appending target 3 with shape (3, 3)\n",
            "(3, 50, 50) (3, 3, 3) (1, 50, 50) (1, 3, 3)\n"
          ]
        }
      ],
      "source": [
        "train_f, train_t, test_f, test_t = get_data(get_coordinates_felix(polygon, target), int(f_date), feature_bands, get_target_image(target))\n",
        "\n",
        "processed_train_f = process_and_expand(train_f)\n",
        "processed_train_t = process_and_expand(train_t)\n",
        "processed_test_f = process_and_expand(test_f)\n",
        "processed_test_t = process_and_expand(test_t)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tjo7UtIShbf",
        "outputId": "e75f4ee6-baa3-4a68-8593-01c66b141b64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4618 - f1_score: 0.0000e+00\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.3587 - f1_score: 0.1429\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.3707 - f1_score: 0.2500\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4467 - f1_score: 0.1176\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.2031 - f1_score: 0.4000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.2127 - f1_score: 0.4000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.1682 - f1_score: 0.4444\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.4010 - f1_score: 0.1429\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1997 - f1_score: 0.2500\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.1549 - f1_score: 0.0000e+00\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.1141 - f1_score: 0.4000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.1136 - f1_score: 0.5000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.1785 - f1_score: 0.2857\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.1493 - f1_score: 0.3333\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.1785 - f1_score: 0.2857\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0782 - f1_score: 0.5000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.1102 - f1_score: 0.6667\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.1087 - f1_score: 0.5714\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.1975 - f1_score: 0.2500\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.1927 - f1_score: 0.0000e+00\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.1949 - f1_score: 0.2500\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0760 - f1_score: 0.6667\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0234 - f1_score: 0.8000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0741 - f1_score: 0.5000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.1981 - f1_score: 0.0000e+00\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.1481 - f1_score: 0.5000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.1503 - f1_score: 0.3333\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.1435 - f1_score: 0.5000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.2553 - f1_score: 0.2222\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.1399 - f1_score: 0.5000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.1421 - f1_score: 0.3333\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.2090 - f1_score: 0.0000e+00\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.1310 - f1_score: 0.3333\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.1111 - f1_score: 0.5714\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.1474 - f1_score: 0.3333\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0741 - f1_score: 0.5000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.1733 - f1_score: 0.2857\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.1470 - f1_score: 0.0000e+00\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.1482 - f1_score: 0.5000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.1482 - f1_score: 0.3333\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0741 - f1_score: 0.5000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0147 - f1_score: 0.8571\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.1111 - f1_score: 0.0000e+00\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0742 - f1_score: 0.5000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.1111 - f1_score: 0.4000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1315 - f1_score: 0.3333\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0742 - f1_score: 0.5000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0760 - f1_score: 0.5000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0741 - f1_score: 0.5000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.1105 - f1_score: 0.5714\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1482 - f1_score: 0.0000e+00\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.1065 - f1_score: 0.4000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0741 - f1_score: 0.5000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0739 - f1_score: 0.6667\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0741 - f1_score: 0.5000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1461 - f1_score: 0.3333\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0370 - f1_score: 0.8000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1481 - f1_score: 0.0000e+00\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0741 - f1_score: 0.5000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.1097 - f1_score: 0.4000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1111 - f1_score: 0.4000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.1107 - f1_score: 0.4000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0836 - f1_score: 0.5714\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0718 - f1_score: 0.5000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0741 - f1_score: 0.5000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0422 - f1_score: 0.8000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.1110 - f1_score: 0.4000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0775 - f1_score: 0.5000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0735 - f1_score: 0.5000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0741 - f1_score: 0.5000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0370 - f1_score: 0.8000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.1111 - f1_score: 0.4000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0741 - f1_score: 0.6667\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.1111 - f1_score: 0.4000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0370 - f1_score: 0.8000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.1106 - f1_score: 0.5714\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.1071 - f1_score: 0.4000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0741 - f1_score: 0.5000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.1356 - f1_score: 0.3333\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0741 - f1_score: 0.5000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0903 - f1_score: 0.0000e+00\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0373 - f1_score: 0.8000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0852 - f1_score: 0.0000e+00\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.1111 - f1_score: 0.4000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.1479 - f1_score: 0.3333\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0739 - f1_score: 0.5000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0753 - f1_score: 0.5000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0768 - f1_score: 0.6667\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0742 - f1_score: 0.7500\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.1111 - f1_score: 0.4000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0740 - f1_score: 0.6667\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0370 - f1_score: 0.8000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0741 - f1_score: 0.7500\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0473 - f1_score: 0.5000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0370 - f1_score: 0.8000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 4.5168e-13 - f1_score: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1069 - f1_score: 0.5714\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0370 - f1_score: 0.8571\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0746 - f1_score: 0.5000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0741 - f1_score: 0.6667\n"
          ]
        }
      ],
      "source": [
        "# Required imports\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, ZeroPadding2D, Dropout, MaxPooling2D, Flatten, Dense, Reshape\n",
        "from tensorflow.keras.metrics import Metric\n",
        "import tensorflow as tf\n",
        "\n",
        "class F1Score(Metric):\n",
        "\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
        "        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
        "        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.round(y_pred)\n",
        "        values = tf.cast(y_true, tf.float32)\n",
        "        predictions = tf.cast(y_pred, tf.float32)\n",
        "        self.true_positives.assign_add(tf.reduce_sum(values * predictions))\n",
        "        self.false_positives.assign_add(tf.reduce_sum((1.0 - values) * predictions))\n",
        "        self.false_negatives.assign_add(tf.reduce_sum(values * (1.0 - predictions)))\n",
        "\n",
        "    def result(self):\n",
        "        precision = self.true_positives / (self.true_positives + self.false_positives + tf.keras.backend.epsilon())\n",
        "        recall = self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
        "        return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
        "\n",
        "\n",
        "\n",
        "input_img = tf.keras.layers.Input(shape=(50, 50, 1))\n",
        "\n",
        "# Convolutional Block 1\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = BatchNormalization()(x) # Add batch normalization for stability\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Dropout(0.25)(x) # Add dropout for regularization\n",
        "\n",
        "# Convolutional Block 2\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Convolutional Block 3\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# Flattening the feature map\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Dense layers\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Dense layer to get the desired number of features\n",
        "x = Dense(3*3*1, activation='sigmoid')(x)\n",
        "\n",
        "# Reshaping to the target shape\n",
        "decoded = Reshape((3, 3, 1))(x)\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.models.Model(input_img, decoded)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=[F1Score()])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    processed_train_f,\n",
        "    processed_train_t,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_wlQlTLrW1Fq"
      },
      "outputs": [],
      "source": [
        "# y_pred = model.predict(processed_test_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ7EIG0TWKhY",
        "outputId": "36abe7b6-b3ab-4ca7-fab1-4142c2baf412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 291ms/step - loss: 0.2222 - f1_score: 0.0000e+00\n",
            "Test Loss: 0.2222222238779068\n",
            "Test F1 Score: 0.0\n"
          ]
        }
      ],
      "source": [
        "loss, f1_score = model.evaluate(processed_test_f, processed_test_t)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test F1 Score:\", f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABstjmDzWXVE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
